{
    "hyperparameters": {
        "optimizer": "Adam",
        "loss-function": "NLLLoss",
        "epochs": 1,
        "learning-rate": [
            0.0035,
            [
                0.00285,
                1
            ],
            [
                0.00232,
                2
            ],
            [
                0.001889,
                3
            ],
            [
                0.0015386,
                4
            ],
            [
                0.001253,
                5
            ],
            [
                0.00102,
                6
            ],
            [
                0.00083,
                7
            ]
        ],
        "batch-size": [
            512,
            [
                612,
                7
            ]
        ],
        "lstm": 3,
        "hidden-size": 200,
        "layers": 1,
        "dropout-chance": 0.5,
        "embedding-size": 200,
        "dense-layer-1": "relu",
        "dense-layer-2": "logsoftmax",
        "bi-directional": false,
        "triple-ngram": true
    },
    "results": {
        "train-accuracy": [
            42.01625,
            74.04885,
            77.72978,
            79.49472,
            80.67974,
            81.55028,
            82.26668,
            82.90402
        ],
        "train-loss": [
            1.986380283235158,
            0.991696727060572,
            0.8655077696653845,
            0.7988247487937893,
            0.7521736541128051,
            0.716169692054559,
            0.6854805977296076,
            0.6586852091389733
        ],
        "validation-accuracy": [
            67.50587,
            74.20275,
            76.38469,
            77.40853,
            77.8617,
            77.9624,
            78.06311,
            77.77778
        ],
        "validation-loss": [
            1.1318849722544353,
            0.9267747402191162,
            0.8641166885693868,
            0.8365944226582845,
            0.8166296680768331,
            0.8047808061043421,
            0.8045739581187566,
            0.8018542230129242
        ]
    }
}